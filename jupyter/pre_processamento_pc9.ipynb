{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3136015-a4b3-48ab-ae55-78b7453c9aab",
   "metadata": {},
   "source": [
    "PC9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "511a72a1-771b-4d87-bd89-d589aa524093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de sentencas: 2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/matheus-\n",
      "[nltk_data]     sales/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/matheus-\n",
      "[nltk_data]     sales/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Baixando os recursos necessários (só precisa rodar uma vez)\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "texto_completo = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "token_sentencas = sent_tokenize(texto_completo, language = 'english')\n",
    "print(f'total de sentencas: {len(token_sentencas)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edb8a727-c6c7-4362-8851-6c4f3faefb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Tokens (Sujos/NLTK): 36411\n",
      "Total de Tokens (Limpos/Regex): 29333\n",
      "Diferença (Pontuações removidas): 7078\n"
     ]
    }
   ],
   "source": [
    "tokens_sujos = word_tokenize(texto_completo, language = 'english')\n",
    "tokens_limpo = [token for token in tokens_sujos if re.match(r'^\\w+$', token)]\n",
    "\n",
    "\n",
    "print(f'Total de Tokens (Sujos/NLTK): {len(tokens_sujos)}')\n",
    "print(f'Total de Tokens (Limpos/Regex): {len(tokens_limpo)}')\n",
    "print(f'Diferença (Pontuações removidas): {len(tokens_sujos) - len(tokens_limpo)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b076f3a-9155-4f05-bb53-4dbe70436e72",
   "metadata": {},
   "source": [
    "diferença re.match(r'^\\w+$', token) vs (re.findall(r'\\w+', texto_completo)), re.findall o NLTK tivesse separado, por exemplo, d'água em ['d', \"'\", 'água'], o re.findall Regex no texto bruto poderia pegar coisas diferentes dependendo de como foi escrito.\n",
    "\n",
    "Na pipeline, você respeita a decisão do tokenizador anterior e apenas remove o que não serve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
