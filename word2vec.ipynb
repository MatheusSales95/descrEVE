{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb286719-b737-4de1-88c7-7181d9f827f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra dos Documentos Processados ---\n",
      "\n",
      "Doc 1: extensão frente fogo atualmente\n",
      "Doc 2: direção vento frente fogo\n",
      "Doc 3: haver risco frente fogo expandir área urbano\n",
      "Doc 4: equipe recurso disponível combater frente fogo\n",
      "Doc 5: condição meteorológico afetar propagação frente fogo\n",
      "\n",
      "--- Vetores (Amostra das primeiras 4 linhas e colunas) ---\n",
      "\n",
      "               afetar  algum  alimentar  análise\n",
      "Solicitação 1     0.0    0.0        0.0      0.0\n",
      "Solicitação 2     0.0    0.0        0.0      0.0\n",
      "Solicitação 3     0.0    0.0        0.0      0.0\n",
      "Solicitação 4     0.0    0.0        0.0      0.0\n",
      "\n",
      "--- Matriz de Similaridade de Cosseno (Amostra 4x4) ---\n",
      "\n",
      "               Solicitação 1  Solicitação 2  Solicitação 3  Solicitação 4\n",
      "Solicitação 1           1.00           0.19           0.13           0.14\n",
      "Solicitação 2           0.19           1.00           0.13           0.14\n",
      "Solicitação 3           0.13           0.13           1.00           0.10\n",
      "Solicitação 4           0.14           0.14           0.10           1.00\n",
      "\n",
      " Similaridade entre Solicit. 1 e 2: 0.19\n",
      "\n",
      " Similaridade entre Solicit. 1 (Fogo) e 16 (Ar): 0.00\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import dot \n",
    "from numpy.linalg import norm\n",
    "from numpy import average\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "except:\n",
    "    print(\"Modelo SpaCy não encontrado. Verifique a instalação.\")\n",
    "\n",
    "solicitacoes = [\n",
    "    \"Qual a extensão da frente de fogo atualmente\",\n",
    "    \"Como está a direção do vento em relação à frente de fogo\",\n",
    "    \"Há risco de a frente de fogo se expandir para áreas urbanas\",\n",
    "    \"Quais são as equipes e recursos disponíveis para combater a frente de fogo\",\n",
    "    \"Como estão as condições meteorológicas afetando a propagação da frente de fogo\",\n",
    "    \"Quais são os planos de evacuação próximos à frente de fogo\",\n",
    "    \"O que a análise de satélite mostra sobre o comportamento da frente de fogo\",\n",
    "    \"Qual é a estratégia atual para conter a frente de fogo\",\n",
    "    \"Há algum foco secundário sendo alimentado pela frente de fogo principal\",\n",
    "    \"A frente de fogo já foi controlada em alguma área ou ainda está em expansão\",\n",
    "    \"Quais medidas estão sendo tomadas para proteger as propriedades próximas à frente de fogo\",\n",
    "    \"Qual a previsão para os próximos dias em relação ao comportamento da frente de fogo\",\n",
    "    \"Existem recursos aéreos disponíveis para combater a frente de fogo\",\n",
    "    \"Quais são os principais obstáculos para o controle da frente de fogo nesta região\",\n",
    "    \"Como o terreno está influenciando a propagação da frente de fogo\",\n",
    "    \"Qual é o índice de qualidade do ar nesta região\",\n",
    "    \"Quais são os níveis de PM2.5 e PM10 atualmente\",\n",
    "    \"Há previsão de piora na qualidade do ar devido aos ventos\",\n",
    "    \"Como a qualidade do ar está afetando a saúde da população local\",\n",
    "    \"Qual é o status da qualidade do ar em áreas de risco\",\n",
    "    \"Quais medidas estão sendo tomadas para melhorar a qualidade do ar\",\n",
    "    \"Como a poluição do ar está impactando os transportes públicos\",\n",
    "    \"Qual é a concentração de ozônio na camada atmosférica nesta área\",\n",
    "    \"Quais fontes estão contribuindo mais para a poluição do ar local\",\n",
    "    \"Há alguma recomendação para pessoas com problemas respiratórios devido à qualidade do ar\",\n",
    "    \"A qualidade do ar piorou nas últimas horas ou está estabilizada\",\n",
    "    \"Como o clima está influenciando a qualidade do ar atualmente\",\n",
    "    \"Há previsão de tempestades ou chuvas que possam melhorar a qualidade do ar\",\n",
    "    \"Quais são as cidades mais afetadas pela poluição do ar no momento\",\n",
    "    \"A qualidade do ar está dentro dos padrões recomendados pela OMS\"\n",
    "]\n",
    "\n",
    "# Normalização\n",
    "def pre_processar(texto):\n",
    "    doc = nlp(texto.lower())\n",
    "    tokens_limpos = []\n",
    "    for token in doc:\n",
    "        # Stop Words e Pontuação\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            # Lematização\n",
    "            tokens_limpos.append(token.lemma_)\n",
    "            \n",
    "    # O Scikit-Learn espera uma string inteira, não uma lista:\n",
    "    return \" \".join(tokens_limpos)\n",
    "\n",
    "# Aplicando a limpeza em todos os documentos por laço for item em solicitações\n",
    "corpus_processado = [pre_processar(item) for item in solicitacoes]\n",
    "\n",
    "# Numerando corpus_processado visualmente\n",
    "print(\"\\n--- Amostra dos Documentos Processados ---\\n\")\n",
    "for i, item in enumerate(corpus_processado[:5]):\n",
    "    print(f\"Doc {i+1}: {item}\")\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "matriz_tfidf = vectorizer.fit_transform(corpus_processado)\n",
    "\n",
    "# Criando índices dinâmicos para N documentos \n",
    "lista_indices = [f\"Solicitação {i+1}\" for i in range(len(solicitacoes))]\n",
    "\n",
    "# Tabulação dos vetores TF-IDF por pandas\n",
    "df_vetores = pd.DataFrame(\n",
    "    matriz_tfidf.toarray(), \n",
    "    columns=vectorizer.get_feature_names_out(),\n",
    "    index=lista_indices\n",
    ")\n",
    "print(\"\\n--- Vetores (Amostra das primeiras 4 linhas e colunas) ---\\n\")\n",
    "print(df_vetores.iloc[:4, :4].round(2))\n",
    "\n",
    "# Calculo cosseno\n",
    "matriz_similaridade = cosine_similarity(matriz_tfidf)\n",
    "\n",
    "# Transformando em DataFrame para visualizar a Matriz Bonita\n",
    "df_sim = pd.DataFrame(\n",
    "    matriz_similaridade,\n",
    "    index=lista_indices,\n",
    "    columns=lista_indices\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Matriz de Similaridade de Cosseno (Amostra 4x4) ---\\n\")\n",
    "print(df_sim.iloc[:4, :4].round(2))\n",
    "\n",
    "# Comparando Doc 1 (Fogo) com Doc 2 (Vento/Fogo)\n",
    "sim_1_2 = df_sim.loc[\"Solicitação 1\", \"Solicitação 2\"]\n",
    "print(f\"\\n Similaridade entre Solicit. 1 e 2: {sim_1_2:.2f}\")\n",
    "\n",
    "# Comparando Doc 1 (Fogo) com Doc 16 (Qualidade do Ar)\n",
    "sim_1_16 = df_sim.loc[\"Solicitação 1\", \"Solicitação 16\"]\n",
    "print(f\"\\n Similaridade entre Solicit. 1 (Fogo) e 16 (Ar): {sim_1_16:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a79a050e-8b35-413f-a53d-278d98a886b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00168282  0.00074303  0.0159577   0.02815004 -0.02906842 -0.02224352\n",
      "  0.0201877   0.02803968 -0.01566963 -0.01175407  0.02306648 -0.00478121\n",
      " -0.01417607  0.02046872 -0.01518739 -0.00567633  0.0089874   0.00310884\n",
      " -0.02588558 -0.02952442  0.02285063  0.01584731  0.02112033  0.00238189\n",
      "  0.01984761 -0.01064484 -0.00295414  0.01802679 -0.0234936  -0.01230363\n",
      " -0.02347484 -0.00290385]\n",
      "[ 0.02980477 -0.02286406 -0.00728182 -0.00606051  0.02524471 -0.01854605\n",
      "  0.00014987 -0.01485107 -0.03001124  0.01564878 -0.02735913 -0.01372091\n",
      " -0.00010466 -0.00093244 -0.02394107  0.03004561  0.0155712   0.02885665\n",
      " -0.02548664  0.01405046 -0.01292666  0.0025802   0.02656878 -0.0139433\n",
      "  0.01412459 -0.02120513 -0.01108605  0.02938091 -0.0049213   0.00100466\n",
      " -0.01294461 -0.0240034 ]\n",
      "[-0.00471253  0.00771811 -0.00277508  0.01729269 -0.0085718   0.0070627\n",
      "  0.01704936  0.0260811  -0.00454294 -0.02877545  0.01365798  0.00178683\n",
      "  0.02325596 -0.00254151 -0.00824504 -0.02735315 -0.00267674  0.00883301\n",
      "  0.01687947  0.02203955 -0.01782225  0.00580881  0.0190277  -0.01499391\n",
      " -0.00971019  0.02124259  0.00509836  0.00059349  0.01085512  0.00068055\n",
      "  0.03005883  0.01581439]\n",
      "\n",
      " cosseno de similaridade entre 'fogo' e 'frente': \n",
      "0.10012986\n",
      "\n",
      " cosseno de similaridade entre 'fogo' e 'ar': \n",
      "-0.026385179\n"
     ]
    }
   ],
   "source": [
    "# Pre-processamento de W2V\n",
    "def processar_texto_token(texto):\n",
    "    doc = nlp(texto)\n",
    "    lista_tokens = []\n",
    "    for sentenca in doc.sents:\n",
    "        tokens_frase = [token.lemma_.lower() for token in sentenca if not token.is_stop and not token.is_punct]\n",
    "        lista_tokens.append(tokens_frase)\n",
    "    return lista_tokens\n",
    "\n",
    "tokens_w2v = []\n",
    "for texto in solicitacoes:\n",
    "    # processar_texto_token retorna uma LISTA DE FRASES (ex: 3 frases)\n",
    "    frases_do_doc = processar_texto_token(texto)\n",
    "    # .extend tira as frases da lista do documento e coloca na lista principal\n",
    "    tokens_w2v.extend(frases_do_doc)\n",
    "\n",
    "\n",
    "# 5. building the word2vec model\n",
    "# Model configuration\n",
    "feature_size = 32  # size of vector representation\n",
    "window_context = 3\n",
    "min_word_count = 1\n",
    "sample = 1e-5\n",
    "w2vec_model = word2vec.Word2Vec(tokens_w2v, vector_size= feature_size,\n",
    "                                window=window_context, min_count= min_word_count,\n",
    "                                sample=sample, epochs = 50)\n",
    "\n",
    "\n",
    "v1 = w2vec_model.wv[\"fogo\"]\n",
    "v2 = w2vec_model.wv[\"frente\"]\n",
    "v3 = w2vec_model.wv[\"ar\"]\n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)\n",
    "print(\"\\n cosseno de similaridade entre 'fogo' e 'frente': \")\n",
    "print(dot(v1,v2)/(norm(v1)*norm(v2)))\n",
    "\n",
    "print(\"\\n cosseno de similaridade entre 'fogo' e 'ar': \")\n",
    "print(dot(v1,v3)/(norm(v1)*norm(v3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
