{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73f9589-f4db-418d-8b61-9b7f13a7d353",
   "metadata": {},
   "source": [
    "Analise Dom Casmurro por lib NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89eec263-aece-46c5-ba34-20de71c3121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto carregado! Total de caracteres: 373504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package machado to /home/matheus-\n",
      "[nltk_data]     sales/nltk_data...\n",
      "[nltk_data]   Package machado is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/matheus-\n",
      "[nltk_data]     sales/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import machado\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Baixando os recursos necessários (só precisa rodar uma vez)\n",
    "# Se der erro no VS Code, certifique-se de que o ambiente tem nltk instalado\n",
    "nltk.download('machado')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Carregando Dom Casmurro\n",
    "texto_completo = machado.raw('romance/marm08.txt')\n",
    "print(f\"Texto carregado! Total de caracteres: {len(texto_completo)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7f05c-0974-4213-ad86-5b08b379d28d",
   "metadata": {},
   "source": [
    "Tokenização -> palavra e sentenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d77a79-4645-4b2a-8e20-24beca3b213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de palavras: 78935\n",
      "total de sentencas: 4116\n"
     ]
    }
   ],
   "source": [
    "#tonkenização\n",
    "#por palavra\n",
    "token_palavras = word_tokenize(texto_completo, language = 'portuguese')\n",
    "#por sentenca\n",
    "token_sentencas = sent_tokenize(texto_completo, language = 'portuguese')\n",
    "\n",
    "print(f'total de palavras: {len(token_palavras)}')\n",
    "print(f'total de sentencas: {len(token_sentencas)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b5035-90af-40f9-9dea-d831c6414483",
   "metadata": {},
   "source": [
    "A diferença está no sentido de que a tokenização de sentenças vai receber um agrupado de palavras que formam a senteça e na tokenização de palavras cada token vai ser uma palavra individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc12bae5-1356-4536-b607-6151c227fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso!\n",
      "Frase: Vi-lhe fazer um gesto para\n",
      "tirá-los outra vez do bolso, mas não passou do gesto; estava amuado.\n",
      "\n",
      "TOKEN           POS (Classe)    EXPLICAÇÃO\n",
      "---------------------------------------------\n",
      "Vi-lhe          VERB            verb\n",
      "fazer           VERB            verb\n",
      "um              DET             determiner\n",
      "gesto           NOUN            noun\n",
      "para            SCONJ           subordinating conjunction\n",
      "\n",
      "               SPACE           space\n",
      "tirá-los        VERB            verb\n",
      "outra           DET             determiner\n",
      "vez             NOUN            noun\n",
      "do              ADP             adposition\n",
      "bolso           NOUN            noun\n",
      ",               PUNCT           punctuation\n",
      "mas             CCONJ           coordinating conjunction\n",
      "não             ADV             adverb\n",
      "passou          VERB            verb\n",
      "do              ADP             adposition\n",
      "gesto           NOUN            noun\n",
      ";               PUNCT           punctuation\n",
      "estava          AUX             auxiliary\n",
      "amuado          ADJ             adjective\n",
      ".               PUNCT           punctuation\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "    print(\"Modelo carregado com sucesso!\")\n",
    "except OSError:\n",
    "    print(\"Precisamos baixar o modelo. Tente rodar no terminal: python -m spacy download pt_core_news_sm\")\n",
    "\n",
    "frase_escolhida = token_sentencas[10]\n",
    "\n",
    "doc = nlp(frase_escolhida)\n",
    "\n",
    "print(f\"Frase: {frase_escolhida}\\n\")\n",
    "print(f\"{'TOKEN':<15} {'POS (Classe)':<15} {'EXPLICAÇÃO'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<15} {token.pos_:<15} {spacy.explain(token.pos_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c38b6-4287-4b53-81bf-5e26cb026e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
